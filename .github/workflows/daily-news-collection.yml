name: Daily News Collection and Summary Generation

on:
  schedule:
    # Run at 8 AM UTC (midnight PST) every day
    - cron: '0 8 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  collect-and-summarize:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow pushing changes back to repo
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas duckduckgo_search anthropic python-dotenv
        echo "✅ Dependencies installed successfully"
        
    - name: Test environment
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: |
        echo "Testing environment setup..."
        python test_environment.py
        
    - name: Collect daily news
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      continue-on-error: true
      run: |
        echo "Starting news collection..."
        echo "Environment check:"
        echo "- Python version: $(python --version)"
        echo "- Current directory: $(pwd)"
        echo "- Available files: $(ls -la)"
        echo "- API key configured: ${ANTHROPIC_API_KEY:+Yes}"
        echo ""
        
        echo "Attempting news collection with timeout..."
        if timeout 20m python collect_all_news.py --daily; then
          echo "✅ News collection completed successfully"
        else
          echo "⚠️ News collection failed or timed out"
          echo "Exit code: $?"
        fi
        
    - name: Check collected data
      run: |
        echo "Checking for collected news data..."
        ls -la data/ || echo "No data directory"
        ls -la data/*daily_combined*.csv 2>/dev/null || echo "No daily_combined CSV files found"
        ls -la data/latest_daily_combined_csv.txt 2>/dev/null || echo "No latest CSV reference file"
        if [ -f "data/latest_daily_combined_csv.txt" ]; then
          echo "Latest CSV reference:"
          cat data/latest_daily_combined_csv.txt
        fi
        
    - name: Generate daily summary JSON
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: |
        echo "Generating summary from available data..."
        echo "Checking what data is available:"
        echo "- Sample data exists: $([ -f 'sample_data.csv' ] && echo 'Yes' || echo 'No')"
        echo "- Data directory exists: $([ -d 'data' ] && echo 'Yes' || echo 'No')"
        
        # First try with latest collected data
        echo "Attempting to generate summary from collected data..."
        if python generate_daily_summary.py 2>&1; then
          echo "✅ Successfully generated summary from collected data"
        elif [ -f "sample_data.csv" ]; then
          echo "⚠️ Using sample data as fallback"
          if python generate_daily_summary.py --file sample_data.csv 2>&1; then
            echo "✅ Successfully generated summary from sample data"
          else
            echo "❌ Sample data generation failed, using test JSON"
            python create_test_json.py
          fi
        else
          echo "⚠️ No data available, creating test JSON"
          python create_test_json.py
        fi
        
    - name: Check generated files
      run: |
        echo "Checking generated files..."
        ls -la daily_summary.json || echo "daily_summary.json not found"
        if [ -f "daily_summary.json" ]; then
          echo "daily_summary.json size: $(wc -c < daily_summary.json) bytes"
          echo "First few lines:"
          head -5 daily_summary.json
        fi
        
    - name: Upload JSON to S3 (Optional)
      if: env.AWS_ACCESS_KEY_ID != ''
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
      run: |
        # Install AWS CLI
        pip install awscli
        # Upload to S3 bucket (replace with your bucket name)
        aws s3 cp daily_summary.json s3://z-news-data/daily_summary.json --acl public-read
        
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add files if they exist
        if [ -f "daily_summary.json" ]; then
          git add daily_summary.json
          echo "Added daily_summary.json"
        fi
        
        if [ -d "data" ]; then
          git add data/ || echo "No data directory to add"
        fi
        
        # Check if there are any changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          echo "Committing changes..."
          git commit -m "Daily news update: $(date +'%Y-%m-%d')"
          echo "Pushing to repository..."
          git push
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}