name: Daily News Collection and Summary Generation

on:
  schedule:
    # Run at 8 AM UTC (midnight PST) every day
    - cron: '0 8 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  collect-and-summarize:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # Allow pushing changes back to repo
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas duckduckgo_search anthropic python-dotenv
        
    - name: Collect daily news
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: |
        echo "Starting news collection..."
        python collect_all_news.py --daily || echo "News collection failed, using existing data"
        
    - name: Generate daily summary JSON
      env:
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      run: |
        echo "Generating summary from available data..."
        # First try with latest data, fall back to test JSON if needed
        python generate_daily_summary.py || python create_test_json.py
        
    - name: Check generated files
      run: |
        echo "Checking generated files..."
        ls -la daily_summary.json || echo "daily_summary.json not found"
        if [ -f "daily_summary.json" ]; then
          echo "daily_summary.json size: $(wc -c < daily_summary.json) bytes"
          echo "First few lines:"
          head -5 daily_summary.json
        fi
        
    - name: Upload JSON to S3 (Optional)
      if: env.AWS_ACCESS_KEY_ID != ''
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: us-east-1
      run: |
        # Install AWS CLI
        pip install awscli
        # Upload to S3 bucket (replace with your bucket name)
        aws s3 cp daily_summary.json s3://z-news-data/daily_summary.json --acl public-read
        
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add files if they exist
        if [ -f "daily_summary.json" ]; then
          git add daily_summary.json
          echo "Added daily_summary.json"
        fi
        
        if [ -d "data" ]; then
          git add data/ || echo "No data directory to add"
        fi
        
        # Check if there are any changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          echo "Committing changes..."
          git commit -m "Daily news update: $(date +'%Y-%m-%d')"
          echo "Pushing to repository..."
          git push
        fi
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}